{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import seaborn as sns\n",
        "from torchvision import models\n",
        "from google.colab import drive # type: ignore\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data.dataset import Dataset\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def frame_extract(path):\n",
        "  vidObj = cv2.VideoCapture(path)\n",
        "  success = 1\n",
        "  while success:\n",
        "      success, image = vidObj.read()\n",
        "      if success:\n",
        "          yield image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_video(vid_path, train_transforms):\n",
        "\ttransform = train_transforms\n",
        "\tcount = 60\n",
        "\tvideo_path = vid_path\n",
        "\tframes = []\n",
        "\tfor i, frame in enumerate(frame_extract(video_path)):\n",
        "\t\tframes.append(transform(frame))\n",
        "\t\tif(len(frames) == count):\n",
        "\t\t\tbreak\n",
        "\tframes = torch.stack(frames)\n",
        "\tframes = frames[:count]\n",
        "\n",
        "\treturn frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "im_size = 112\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms = transforms.Compose([\n",
        "transforms.ToPILImage(),\n",
        "transforms.Resize((im_size, im_size)),\n",
        "transforms.ToTensor(),\n",
        "transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "video_fil = glob.glob('/content/drive/My Drive/Celeb_fake_face_only/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/My Drive/Celeb_real_face_only/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/My Drive/DFDC_FAKE_Face_only_data/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/My Drive/DFDC_REAL_Face_only_data/*.mp4')\n",
        "video_fil += glob.glob('/content/drive/My Drive/FF_Face_only_data/*.mp4')\n",
        "\n",
        "print(\"Total no of videos :\" , len(video_fil))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = 0\n",
        "\n",
        "for i in video_fil:\n",
        "  try:\n",
        "    count += 1\n",
        "    validate_video(i, transforms)\n",
        "  except:\n",
        "    print(\"Number of video processed: \" , count ,\" Remaining : \" , (len(video_fil) - count))\n",
        "    print(\"Corrupted video is : \" , i)\n",
        "    continue\n",
        "\n",
        "print(f\"Total Corrupted Videos: {(len(video_fil) - count)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CEIygy8uDFXc"
      },
      "outputs": [],
      "source": [
        "frame_count = []\n",
        "\n",
        "for video_file in video_fil:\n",
        "  cap = cv2.VideoCapture(video_file)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 60):\n",
        "    video_fil.remove(video_file)\n",
        "    continue\n",
        "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "print(\"frames are \" , frame_count)\n",
        "print(\"Total no of video: \" , len(frame_count))\n",
        "print('Average frame per video:', np.mean(frame_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OqGXNkqhDKZU"
      },
      "outputs": [],
      "source": [
        "class video_dataset(Dataset):\n",
        "\tdef __init__(self, video_names, labels, sequence_length = 60, transform = None):\n",
        "\t\t\tself.video_names = video_names\n",
        "\t\t\tself.labels = labels\n",
        "\t\t\tself.transform = transform\n",
        "\t\t\tself.count = sequence_length\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\t\treturn len(self.video_names)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\t\tvideo_path = self.video_names[idx]\n",
        "\t\t\tframes = []\n",
        "\t\t\ttemp_video = video_path.split('/')[-1]\n",
        "\t\t\tlabel = self.labels.iloc[(label.loc[label[\"file\"] == temp_video].index.values[0]), 1]\n",
        "\t\t\tif(label == 'FAKE'):\n",
        "\t\t\t\tlabel = 0\n",
        "\t\t\tif(label == 'REAL'):\n",
        "\t\t\t\tlabel = 1\n",
        "\t\t\tfor i, frame in enumerate(self.frame_extract(video_path)):\n",
        "\t\t\t\tframes.append(self.transform(frame))\n",
        "\t\t\t\tif(len(frames) == self.count):\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\tframes = torch.stack(frames)\n",
        "\t\t\tframes = frames[:self.count]\n",
        "\n",
        "\t\t\treturn frames, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1leMozhXa5LF"
      },
      "outputs": [],
      "source": [
        "def number_of_real_and_fake_videos(data_list):\n",
        "  header_list = [\"file\", \"label\"]\n",
        "  lab = pd.read_csv('/content/drive/My Drive/Gobal_metadata.csv', names = header_list)\n",
        "  fake = 0\n",
        "  real = 0\n",
        "  for i in data_list:\n",
        "    temp_video = i.split('/')[-1]\n",
        "    label = lab.iloc[(label.loc[label[\"file\"] == temp_video].index.values[0]), 1]\n",
        "    if(label == 'FAKE'):\n",
        "      fake += 1\n",
        "    if(label == 'REAL'):\n",
        "      real += 1\n",
        "  return real, fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sWMZn0YHDO2b"
      },
      "outputs": [],
      "source": [
        "header_list = [\"file\", \"label\"]\n",
        "labels = pd.read_csv('/content/drive/My Drive/Gobal_metadata.csv', names = header_list)\n",
        "\n",
        "train_videos = video_fil[:int(0.8 * len(video_fil))]\n",
        "test_videos = video_fil[int(0.8 * len(video_fil)):]\n",
        "\n",
        "print(\"train : \" , len(train_videos))\n",
        "print(\"test : \" , len(test_videos))\n",
        "\n",
        "print(\"TRAIN: \", \"Real:\",number_of_real_and_fake_videos(train_videos)[0],\" Fake:\",number_of_real_and_fake_videos(train_videos)[1])\n",
        "print(\"TEST: \", \"Real:\",number_of_real_and_fake_videos(test_videos)[0],\" Fake:\",number_of_real_and_fake_videos(test_videos)[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = video_dataset(train_videos, labels, sequence_length = 60, transform = transforms)\n",
        "test_data = video_dataset(test_videos, labels, sequence_length = 60, transform = transforms)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 4, shuffle = True, num_workers = 4)\n",
        "test_loader = DataLoader(test_data, batch_size = 4, shuffle = True, num_workers = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UtOXSqyBDRnD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\tdef __init__(self, num_classes, latent_dim = 2048, lstm_layers = 1, hidden_dim = 2048, bidirectional = False):\n",
        "\t\tsuper(Model, self).__init__()\n",
        "\t\tmodel = models.resnext50_32x4d(pretrained = True)\n",
        "\t\tself.model = nn.Sequential(*list(model.children())[:-2])\n",
        "\t\tself.lstm = nn.LSTM(latent_dim, hidden_dim, lstm_layers, bidirectional)\n",
        "\t\tself.relu = nn.LeakyReLU()\n",
        "\t\tself.dp = nn.Dropout(0.4)\n",
        "\t\tself.linear1 = nn.Linear(2048, num_classes)\n",
        "\t\tself.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tbatch_size, seq_length, c, h, w = x.shape\n",
        "\t\tx = x.view(batch_size * seq_length, c, h, w)\n",
        "\t\tfmap = self.model(x)\n",
        "\t\tx = self.avgpool(fmap)\n",
        "\t\tx = x.view(batch_size, seq_length, 2048)\n",
        "\t\tx_lstm, _ = self.lstm(x, None)\n",
        "\n",
        "\t\treturn fmap, self.dp(self.linear1(torch.mean(x_lstm, dim = 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WYNhn10tDV90"
      },
      "outputs": [],
      "source": [
        "model = Model(2).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AverageMeter(object):\n",
        "\tdef __init__(self):\n",
        "\t\tself.reset()\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.val = 0\n",
        "\t\tself.avg = 0\n",
        "\t\tself.sum = 0\n",
        "\t\tself.count = 0\n",
        "\n",
        "\tdef update(self, val):\n",
        "\t\tself.val = val\n",
        "\t\tself.sum += val\n",
        "\t\tself.count += 1\n",
        "\t\tself.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_accuracy(outputs, targets):\n",
        "\tbatch_size = targets.size(0)\n",
        "\t_, pred = outputs.topk(1, 1, True)\n",
        "\tpred = pred.t()\n",
        "\tcorrect = pred.eq(targets.view(1, -1))\n",
        "\tn_correct_elems = correct.float().sum().item()\n",
        "\n",
        "\treturn 100 * n_correct_elems / batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FKheLUWBDaNN"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch, num_epochs, data_loader, model, criterion, optimizer):\n",
        "\tmodel.train()\n",
        "\tlosses = AverageMeter()\n",
        "\taccuracies = AverageMeter()\n",
        "\n",
        "\tfor i, (inputs, targets) in enumerate(data_loader):\n",
        "\t\tif torch.cuda.is_available():\n",
        "\t\t\t\ttargets = targets.type(torch.cuda.LongTensor)\n",
        "\t\t\t\tinputs = inputs.cuda()\n",
        "\t\t_,outputs = model(inputs)\n",
        "\t\tloss  = criterion(outputs, targets.type(torch.cuda.LongTensor))\n",
        "\t\tacc = calculate_accuracy(outputs, targets.type(torch.cuda.LongTensor))\n",
        "\t\tlosses.update(loss.item(), inputs.size(0))\n",
        "\t\taccuracies.update(acc, inputs.size(0))\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tsys.stdout.write(\n",
        "\t\t\t\"\\r[Epoch %d/%d] [Batch %d / %d] [Loss: %f, Acc: %.2f%%]\"\n",
        "\t\t\t% (\n",
        "\t\t\t\t\tepoch,\n",
        "\t\t\t\t\tnum_epochs,\n",
        "\t\t\t\t\ti,\n",
        "\t\t\t\t\tlen(data_loader),\n",
        "\t\t\t\t\tlosses.avg,\n",
        "\t\t\t\t\taccuracies.avg))\n",
        "\n",
        "\ttorch.save(model.state_dict(), '/content/checkpoint.pt')\n",
        "\n",
        "\treturn losses.avg,accuracies.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, data_loader ,criterion):\n",
        "\tprint('Testing')\n",
        "\tmodel.eval()\n",
        "\tlosses = AverageMeter()\n",
        "\taccuracies = AverageMeter()\n",
        "\tpred = []\n",
        "\ttrue = []\n",
        "\tcount = 0\n",
        "\twith torch.no_grad():\n",
        "\t\tfor i, (inputs, targets) in enumerate(data_loader):\n",
        "\t\t\t\tif torch.cuda.is_available():\n",
        "\t\t\t\t\t\ttargets = targets.cuda().type(torch.cuda.FloatTensor)\n",
        "\t\t\t\t\t\tinputs = inputs.cuda()\n",
        "\t\t\t\t_,outputs = model(inputs)\n",
        "\t\t\t\tloss = torch.mean(criterion(outputs, targets.type(torch.cuda.LongTensor)))\n",
        "\t\t\t\tacc = calculate_accuracy(outputs,targets.type(torch.cuda.LongTensor))\n",
        "\t\t\t\t_,p = torch.max(outputs, 1) \n",
        "\t\t\t\ttrue += (targets.type(torch.cuda.LongTensor)).detach().cpu().numpy().reshape(len(targets)).tolist()\n",
        "\t\t\t\tpred += p.detach().cpu().numpy().reshape(len(p)).tolist()\n",
        "\t\t\t\tlosses.update(loss.item(), inputs.size(0))\n",
        "\t\t\t\taccuracies.update(acc, inputs.size(0))\n",
        "\t\t\t\tsys.stdout.write(\n",
        "\t\t\t\t\t\"\\r[Batch %d / %d]  [Loss: %f, Acc: %.2f%%]\"\n",
        "\t\t\t\t\t% (\n",
        "\t\t\t\t\t\t\ti,\n",
        "\t\t\t\t\t\t\tlen(data_loader),\n",
        "\t\t\t\t\t\t\tlosses.avg,\n",
        "\t\t\t\t\t\t\taccuracies.avg\n",
        "\t\t\t\t\t\t\t)\n",
        "\t\t\t\t\t)\n",
        "\t\tprint('\\nAccuracy {}'.format(accuracies.avg))\n",
        "\n",
        "\treturn true, pred, losses.avg,accuracies.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "b8WneBZNfysN"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(y_true, y_pred):\n",
        "\tcm = confusion_matrix(y_true, y_pred)\n",
        "\tprint('True positive = ', cm[0][0])\n",
        "\tprint('False positive = ', cm[0][1])\n",
        "\tprint('False negative = ', cm[1][0])\n",
        "\tprint('True negative = ', cm[1][1])\n",
        "\tprint('\\n')\n",
        "\tdf_cm = pd.DataFrame(cm, range(2), range(2))\n",
        "\tsns.set(font_scale=1.4)\n",
        "\tsns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
        "\tplt.ylabel('Actual label', size = 20)\n",
        "\tplt.xlabel('Predicted label', size = 20)\n",
        "\tplt.xticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "\tplt.yticks(np.arange(2), ['Fake', 'Real'], size = 16)\n",
        "\tplt.ylim([2, 0])\n",
        "\tplt.show()\n",
        "\tcalculated_acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
        "\tprint(\"Calculated Accuracy\", calculated_acc * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fExJLjt2AtV9"
      },
      "outputs": [],
      "source": [
        "def plot_loss(train_loss_avg, test_loss_avg, num_epochs):\n",
        "  loss_train = train_loss_avg\n",
        "  loss_val = test_loss_avg\n",
        "  print(num_epochs)\n",
        "  epochs = range(1, num_epochs + 1)\n",
        "  plt.plot(epochs, loss_train, 'g', label = 'Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label = 'validation loss')\n",
        "  plt.title('Training and Validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_accuracy(train_accuracy, test_accuracy, num_epochs):\n",
        "  loss_train = train_accuracy\n",
        "  loss_val = test_accuracy\n",
        "  epochs = range(1, num_epochs + 1)\n",
        "  plt.plot(epochs, loss_train, 'g', label = 'Training accuracy')\n",
        "  plt.plot(epochs, loss_val, 'b', label = 'validation accuracy')\n",
        "  plt.title('Training and Validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rUe1XrYnDdit"
      },
      "outputs": [],
      "source": [
        "lr = 1e-5\n",
        "num_epochs = 20\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = lr, weight_decay = 1e-5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "train_loss_avg =[]\n",
        "train_accuracy = []\n",
        "test_loss_avg = []\n",
        "test_accuracy = []\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "\tl, acc = train_epoch(epoch, num_epochs, train_loader, model, criterion, optimizer)\n",
        "\ttrain_loss_avg.append(l)\n",
        "\ttrain_accuracy.append(acc)\n",
        "\ttrue,pred,tl,t_acc = test(model, test_loader, criterion)\n",
        "\ttest_loss_avg.append(tl)\n",
        "\ttest_accuracy.append(t_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss(train_loss_avg, test_loss_avg, len(train_loss_avg))\n",
        "plot_accuracy(train_accuracy, test_accuracy, len(train_accuracy))\n",
        "print_confusion_matrix(true, pred)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model_and_train_csv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
